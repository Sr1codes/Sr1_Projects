{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75efe22",
   "metadata": {},
   "source": [
    "# COSC-Project 02\n",
    "**Srivathsav Arumugam**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36567da4",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The purpose of this project is to define functions in .py file, as well to use a text file to determine word counts,\n",
    "file tokenization. We will use the novel \"A tale of two cities\". this is the txt file we will use to perform text analysis. \n",
    "\n",
    "I will use this notebook to test the functions I have created in the word_count.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f60565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_count .py-> will have all functions\n",
    "#Project2.ipynb -> Call functions from here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "349c9593",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i word_count.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8624f3d",
   "metadata": {},
   "source": [
    "## Testing the process_word() Function\n",
    "we will test this function using a few strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87e14ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "what\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(process_word('Test!')) \n",
    "print(process_word('WHAT?!?!?'))\n",
    "print(process_word('!_(:;hEl\\'lO?,)123'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb5fd8",
   "metadata": {},
   "source": [
    "## Testing the process_line() function\n",
    "We will use a test string to test the process_line() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f8d0213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'test', 'string', 'its', 'fifty', 'eight', 'characters', 'long']\n"
     ]
    }
   ],
   "source": [
    "test_string = 'This is a \"test string\". It\\'s fifty-eight characters long!'\n",
    "out = process_line(test_string)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dfd164",
   "metadata": {},
   "source": [
    "## Processing the File\n",
    "We will now use the process_file() function to read and process the contents of the file tale_of_two_cities.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cca59c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 137149 words contained in the file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = process_file('tale_of_two_cities.txt')\n",
    "print(f\"There are {len(words)} words contained in the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917cf93f",
   "metadata": {},
   "source": [
    "#### We will now print the first few words contained in the novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a036c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'tale', 'of', 'two', 'cities', 'a', 'story', 'of', 'the', 'french', 'revolution', 'by', 'charles', 'dickens', 'book', 'the', 'first', 'recalled', 'to', 'life']\n"
     ]
    }
   ],
   "source": [
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71e1ec",
   "metadata": {},
   "source": [
    "## Unique Words\n",
    "We will now determine the number of unique words in the novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac97d5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9789 unique words contained in the file.\n"
     ]
    }
   ],
   "source": [
    "unique = find_unique(words)\n",
    "print(f\"There are {len(unique)} unique words contained in the file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e59f98",
   "metadata": {},
   "source": [
    "## Word Frequency\n",
    "We will now create a dictionary containing word counts in the novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "480b24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word \"hand\" appears 250 times in the file.\n",
      "The word \"face\" appears 187 times in the file.\n",
      "The word \"day\" appears 197 times in the file.\n",
      "The word \"night\" appears 217 times in the file.\n"
     ]
    }
   ],
   "source": [
    "freq = find_frequency(words) #freq per word\n",
    "some_words = ['hand', 'face', 'day', 'night']\n",
    "for w in some_words:\n",
    "    print(f'The word \"{w}\" appears {freq[w]} times in the file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827f8e9",
   "metadata": {},
   "source": [
    "## Most common Words\n",
    "We will attempt to find and display a list of the 20 most commonly occuring words in A Tale of Two Cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa29bd17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word      Count\n",
      "----------------\n",
      "the          8025\n",
      "and          4999\n",
      "of           4009\n",
      "to           3569\n",
      "a            2946\n",
      "in           2599\n",
      "it           2032\n",
      "his          2011\n",
      "i            1942\n",
      "that         1911\n",
      "he           1845\n",
      "was          1773\n",
      "you          1400\n",
      "with         1311\n",
      "had          1306\n",
      "as           1163\n",
      "her          1045\n",
      "at           1033\n",
      "him           976\n",
      "for           960\n"
     ]
    }
   ],
   "source": [
    "word_freq = find_frequency(words)\n",
    "most_common(word_freq, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba92812",
   "metadata": {},
   "source": [
    "## Counting Words by length \n",
    "We will display information concerning the distrubution of lengths of unique words found in the novel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2ec850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length Count\n",
      "----------------\n",
      "17              1\n",
      "16              4\n",
      "15             17\n",
      "14             44\n",
      "13            135\n",
      "12            261\n",
      "11            492\n",
      "10            786\n",
      "9            1177\n",
      "8            1442\n",
      "7            1602\n",
      "6            1556\n",
      "5            1141\n",
      "4             804\n",
      "3             256\n",
      "2              56\n",
      "1              15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unique_words = find_unique(words)\n",
    "count_by_length(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7c00a",
   "metadata": {},
   "source": [
    "## Stop words \n",
    "We will now create a list of commonly occuring \"stop words\" these will be removed from the words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52a538b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 668 words in our list of stop words.\n"
     ]
    }
   ],
   "source": [
    "stop = process_file(\"stopwords.txt\")\n",
    "print(f\"There are {len(stop)} words in our list of stop words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d93e90e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'able', 'about', 'above', 'abst', 'accordance', 'according', 'accordingly', 'across', 'act', 'actually', 'added', 'adj', 'affected', 'affecting', 'affects', 'after', 'afterwards', 'again', 'against', 'ah', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'announce', 'another', 'any', 'anybody', 'anyhow', 'anymore', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apparently', 'approximately', 'are', 'aren', 'arent']\n"
     ]
    }
   ],
   "source": [
    "print(stop[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb002bd",
   "metadata": {},
   "source": [
    "## Counting Non-Stop words \n",
    "We will now display the number of non-stop words and the number of unique non-stop words found in the novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8cf2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 49266 non-stop words contained in the file.\n",
      "There are 9279 unique non-stop words contained in the file.\n"
     ]
    }
   ],
   "source": [
    "words_non_stop = remove_stop(words, stop)\n",
    "unique_non_stop = remove_stop(unique, stop)\n",
    "\n",
    "print(f\"There are {len(words_non_stop)} non-stop words contained in the file.\")\n",
    "print(f\"There are {len(unique_non_stop)} unique non-stop words contained in the file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deb3f7",
   "metadata": {},
   "source": [
    " ## Counting words by First letter\n",
    " We will display the number of unique words with each possible first letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8847fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter Count\n",
      "----------------\n",
      "a             622\n",
      "b             498\n",
      "c             911\n",
      "d             664\n",
      "e             413\n",
      "f             509\n",
      "g             307\n",
      "h             350\n",
      "i             406\n",
      "j              77\n",
      "k              66\n",
      "l             334\n",
      "m             410\n",
      "n             161\n",
      "o             227\n",
      "p             697\n",
      "q              42\n",
      "r             596\n",
      "s            1211\n",
      "t             495\n",
      "u             246\n",
      "v             132\n",
      "w             359\n",
      "x              15\n",
      "y              40\n",
      "z               1\n"
     ]
    }
   ],
   "source": [
    "unique_words = find_unique(words)\n",
    "count_by_first(unique_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
